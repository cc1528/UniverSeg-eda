{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb55b6a5",
   "metadata": {},
   "source": "# results"
  },
  {
   "cell_type": "code",
   "id": "548a2da9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T17:43:51.127175Z",
     "start_time": "2024-05-23T17:43:45.445691Z"
    }
   },
   "source": [
    "import math\n",
    "import itertools\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import einops as E\n",
    "\n",
    "import pathlib\n",
    "import os\n",
    "import subprocess\n",
    "from dataclasses import dataclass\n",
    "from typing import Literal, Optional, Tuple\n",
    "from torch.utils.data import Dataset\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T17:43:52.854684Z",
     "start_time": "2024-05-23T17:43:52.623135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import universeg\n",
    "# print(universeg.__version__)\n"
   ],
   "id": "e252c61cd3e1a5e7",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydantic'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01muniverseg\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(universeg\u001B[38;5;241m.\u001B[39m__version__)\n",
      "File \u001B[1;32m~\\Documentos\\ams\\data_science\\actual_thesis\\codes\\MedSAM_Universeg_2024\\UniverSeg-eda\\UniverSeg-main\\universeg\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01muniverseg\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m UniverSeg, CrossBlock, CrossConv2d, universeg\n",
      "File \u001B[1;32m~\\Documentos\\ams\\data_science\\actual_thesis\\codes\\MedSAM_Universeg_2024\\UniverSeg-eda\\UniverSeg-main\\universeg\\model.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdataclasses\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dataclass\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Any, Dict, List, Literal, Optional, Tuple, Union\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpydantic\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m validate_call\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01meinops\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mE\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pydantic'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "f9a5055b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T17:44:16.557905Z",
     "start_time": "2024-05-23T17:44:16.489156Z"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.append('UniverSeg')\n",
    "\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "from universeg import universeg\n",
    "model = universeg(pretrained=True)\n",
    "_ = model.to(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydantic'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m device \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(device)\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01muniverseg\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m universeg\n\u001B[0;32m      9\u001B[0m model \u001B[38;5;241m=\u001B[39m universeg(pretrained\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     10\u001B[0m _ \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\Documentos\\ams\\data_science\\actual_thesis\\codes\\MedSAM_Universeg_2024\\UniverSeg-eda\\UniverSeg-main\\universeg\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01muniverseg\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m UniverSeg, CrossBlock, CrossConv2d, universeg\n",
      "File \u001B[1;32m~\\Documentos\\ams\\data_science\\actual_thesis\\codes\\MedSAM_Universeg_2024\\UniverSeg-eda\\UniverSeg-main\\universeg\\model.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdataclasses\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dataclass\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Any, Dict, List, Literal, Optional, Tuple, Union\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpydantic\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m validate_call\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01meinops\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mE\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pydantic'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "9f70d6b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T16:50:46.833145Z",
     "start_time": "2024-05-23T16:50:46.833049Z"
    }
   },
   "source": [
    "    # Define input and mask folders for the JNU_FMI dataset\n",
    "    test_input_folder = r'C:\\Users\\cinth\\Documentos\\ams\\data_science\\actual_thesis\\codes\\MedSAM_Universeg_2024\\datasets\\data\\partitioned_dataset\\images\\test'\n",
    "    test_mask_folder =  r'C:\\Users\\cinth\\Documentos\\ams\\data_science\\actual_thesis\\codes\\Universeg-main\\UniverSeg-main\\example_data\\partitioned_dataset\\masks\\test'\n",
    "    \n",
    "    support_input_folder = r'C:\\Users\\cinth\\Documentos\\ams\\data_science\\actual_thesis\\codes\\Universeg-main\\UniverSeg-main\\example_data\\partitioned_dataset\\images\\train'\n",
    "    support_mask_folder =  r'C:\\Users\\cinth\\Documentos\\ams\\data_science\\actual_thesis\\codes\\Universeg-main\\UniverSeg-main\\example_data\\partitioned_dataset\\masks\\train'\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9354bf3e",
   "metadata": {},
   "source": [
    "def visualize_tensors(tensors, col_wrap=8, col_names=None, title=None, figsize=(15, 15)):\n",
    "    M = len(tensors)\n",
    "    N = len(next(iter(tensors.values())))\n",
    "\n",
    "    cols = col_wrap\n",
    "    rows = math.ceil(N/cols) * M\n",
    "\n",
    "    d = 2.5\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(d*cols, d*rows))\n",
    "    if rows == 1:\n",
    "      axes = axes.reshape(1, cols)\n",
    "\n",
    "    for g, (grp, tensors) in enumerate(tensors.items()):\n",
    "        for k, tensor in enumerate(tensors):\n",
    "            col = k % cols\n",
    "            row = g + M*(k//cols)\n",
    "            x = tensor.detach().cpu().numpy().astype(np.float32).squeeze()\n",
    "            ax = axes[row,col]\n",
    "            if len(x.shape) == 2:\n",
    "                ax.imshow(x,vmin=0, vmax=1, cmap='gray')\n",
    "            else:\n",
    "                ax.imshow(E.rearrange(x,'C H W -> H W C'))\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(grp, fontsize=16)\n",
    "            if col_names is not None and row == 0:\n",
    "                ax.set_title(col_names[col])\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            ax = axes[i,j]\n",
    "            ax.grid(False)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "    if title:\n",
    "        plt.suptitle(title, fontsize=20)\n",
    "\n",
    "    plt.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fa4cfb31",
   "metadata": {},
   "source": [
    "# Dice metric for measuring volume agreement\n",
    "def dice_score(y_pred: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "    y_pred = y_pred.long()\n",
    "    y_true = y_true.long()\n",
    "    score = 2*(y_pred*y_true).sum() / (y_pred.sum() + y_true.sum())\n",
    "    return score.item()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bf9bae08",
   "metadata": {},
   "source": [
    "#Accuracy score implemented\n",
    "def accuracy_score(y_pred: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "    y_pred = y_pred.long()\n",
    "    y_true = y_true.long()\n",
    "    correct = (y_pred == y_true).sum().item()\n",
    "    total = y_true.numel()\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    return accuracy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "31f084cf",
   "metadata": {},
   "source": [
    "def sensitivity_score(y_pred: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "    y_pred = y_pred.long()\n",
    "    y_true = y_true.long()\n",
    "    true_positives = ((y_pred == 1) & (y_true == 1)).sum().item()\n",
    "    false_negatives = ((y_pred == 0) & (y_true == 1)).sum().item()\n",
    "    sensitivity = true_positives / (true_positives + false_negatives) if true_positives + false_negatives != 0 else 0\n",
    "\n",
    "    return sensitivity"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "52149643",
   "metadata": {},
   "source": [
    "def precision_score(y_pred: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "    y_pred = y_pred.long()\n",
    "    y_true = y_true.long()\n",
    "    true_positives = ((y_pred == 1) & (y_true == 1)).sum().item()\n",
    "    false_positives = ((y_pred == 1) & (y_true == 0)).sum().item()\n",
    "    precision = true_positives / (true_positives + false_positives) if true_positives + false_positives != 0 else 0\n",
    "\n",
    "    return precision"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f12b9c04",
   "metadata": {},
   "source": [
    "def jaccard_score(y_pred: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "    y_pred = y_pred.long()\n",
    "    y_true = y_true.long()\n",
    "    intersection = ((y_pred == 1) & (y_true == 1)).sum().item()\n",
    "    union = ((y_pred == 1) | (y_true == 1)).sum().item()\n",
    "    jaccard = intersection / union if union != 0 else 0\n",
    "\n",
    "    return jaccard"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3309a112",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "def process_image(image_path: pathlib.Path, seg_mask_path: pathlib.Path, size: Tuple[int, int], augment: bool = False) -> np.ndarray:\n",
    "    \"\"\"Process input image with hot encoded selection of areas.\"\"\"\n",
    "    # Load input image\n",
    "    img = PIL.Image.open(image_path)\n",
    "    img = img.resize(size, resample=PIL.Image.BILINEAR)\n",
    "    img = img.convert(\"L\")\n",
    "    img = np.array(img)\n",
    "    img = img.astype(np.float32)\n",
    "    return img\n",
    "#     \n",
    "\n",
    "\n",
    "def process_seg(path: pathlib.Path, size: Tuple[int, int]) -> np.ndarray:\n",
    "    \"\"\"Process segmentation mask.\"\"\"\n",
    "    seg = PIL.Image.open(path)\n",
    "    seg = seg.resize(size, resample=PIL.Image.NEAREST)\n",
    "    seg = seg.convert(\"L\")\n",
    "    seg = np.array(seg)\n",
    "\n",
    "    # One-hot encoded representation of segmentation mask\n",
    "    # seg_mask = np.stack([seg == 0, seg == 128, seg == 255])\n",
    "    # seg = seg_mask.astype(np.float32)\n",
    "    #seg = np.expand_dims(seg == 255, axis=0)\n",
    "    seg = np.expand_dims(seg > 0, axis=0)\n",
    "    return seg.astype(np.float32)\n",
    "\n",
    "    #return seg\n",
    "\n",
    "def apply_rois(image: np.ndarray, seg_mask: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Apply regions of interest (ROIs) from segmentation mask to input image.\"\"\"\n",
    "    # Apply the mask to the input image\n",
    "    img_with_rois = np.where(seg_mask[0], image, 0)\n",
    "    img_with_rois = img_with_rois.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "    return img_with_rois\n",
    "\n",
    "\n",
    "def load_dataset(input_folder: str, mask_folder: str, size: Tuple[int, int] = (128, 128)):\n",
    "    \"\"\"Load dataset from input and mask folders.\"\"\"\n",
    "    data = []\n",
    "    input_path = pathlib.Path(input_folder)\n",
    "    mask_path = pathlib.Path(mask_folder)\n",
    "\n",
    "    # Sort images based on numerical values in filenames\n",
    "    input_files = sorted(input_path.glob(\"*.png\"), key=lambda x: int(x.stem.split('_')[-1]))\n",
    "        \n",
    "    count = 1\n",
    "    for file in input_files:\n",
    "        img = process_image(file,mask_path, size=size)\n",
    "        img_name = file.stem\n",
    "\n",
    "        # Load segmentation mask\n",
    "        seg_file = mask_path / f\"{img_name}_mask.png\"\n",
    "        if seg_file.exists():\n",
    "            seg = process_seg(seg_file, size=size)\n",
    "        else:\n",
    "            print(f\"Mask file '{seg_file}' not found. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Apply regions of interest (ROIs) to input image\n",
    "        #img_with_co = apply_rois(img, seg)\n",
    "\n",
    "        data.append((img / 255.0, seg))\n",
    "        count+=1\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class JNU_FMI:\n",
    "    input_folder: str\n",
    "    label: str\n",
    "    size: Tuple[int, int] = (128, 128)\n",
    "    label_name: Optional[Literal[\"head\", \"symp\", \"background\"]] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self._data = load_dataset(self.input_folder, self.label, size=self.size)\n",
    "        T = torch.from_numpy\n",
    "        \n",
    "        # Assign indices based on sorted filenames\n",
    "        self._data = [(T(x)[None], T(y)) for x, y in self._data]\n",
    "         \n",
    "        \n",
    "        if self.label is not None:\n",
    "            self.masks = sorted(os.listdir(self.label), key=lambda x: int(x.split('_')[-2]))\n",
    "            if self.label in self.masks:\n",
    "                self._ilabel = {\"head\": 1, \"symp\": 2, \"background\": 0}[self.label]\n",
    "        \n",
    "        self.idxs = list(range(len(self._data)))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, seg = self._data[self.idxs[idx]]\n",
    "        # if self.label is not None:\n",
    "        #     seg = seg[self.label_name][None]\n",
    "        return img, seg"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5416928c",
   "metadata": {},
   "source": [
    "@torch.no_grad()\n",
    "def inferencesupport(model, image, label, support_images, support_labels):\n",
    "    image, label = image.to(device), label.to(device)\n",
    "\n",
    "    # inference\n",
    "    logits = model(\n",
    "        image[None],\n",
    "        support_images[None],\n",
    "        support_labels[None]\n",
    "    )[0] # outputs are logits\n",
    "\n",
    "    soft_pred = torch.sigmoid(logits)\n",
    "    hard_pred = soft_pred.round().clip(0,1)\n",
    "\n",
    "    #  score\n",
    "    dicescore = dice_score(hard_pred, label)\n",
    "    accuracy = accuracy_score(hard_pred,label)\n",
    "    sensitivity =sensitivity_score(hard_pred,label)\n",
    "    precision=precision_score(hard_pred,label)\n",
    "    jaccard=jaccard_score(hard_pred,label)\n",
    "\n",
    "    # return a dictionary of all relevant variables\n",
    "    return {'Image': image,\n",
    "            'Soft Prediction': soft_pred,\n",
    "            'Prediction': hard_pred,\n",
    "            'Ground Truth': label,\n",
    "            'score': dicescore,\n",
    "            'accuracy' : accuracy,\n",
    "            'sensitivity':sensitivity,\n",
    "            'precision':precision,\n",
    "            'jaccard' : jaccard}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0fc29a5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#support_images, support_labels = zip(*itertools.islice(d_support, n_support))\n",
    "#support_images = torch.stack(support_images).to(device)\n",
    "#support_labels = torch.stack(support_labels).to(device)\n",
    "import random\n",
    "n_support = 64\n",
    "\n",
    "d_support = JNU_FMI(support_input_folder, label=support_mask_folder)\n",
    "d_test = JNU_FMI(test_input_folder, label=test_mask_folder)\n",
    "\n",
    "# Create a list of indices\n",
    "#indices = list(range(len(d_support)))\n",
    "\n",
    "# Shuffle the indices\n",
    "#random.shuffle(indices)\n",
    "\n",
    "# Select n_support random indices\n",
    "#random_indices = indices[:n_support]\n",
    "\n",
    "# Use the selected random indices to extract corresponding elements from d_support\n",
    "#random_support = [d_support[i] for i in random_indices]\n",
    "\n",
    "# Unzip the random_support into images and labels\n",
    "#support_images, support_labels = zip(*random_support)\n",
    "\n",
    "# Convert support_images into a PyTorch tensor and move it to the device\n",
    "#support_images = torch.stack(support_images).to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "68f1374e",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "support_set_sizes = [1, 2, 4, 8, 16, 32, 64]\n",
    "\n",
    "# Create empty DataFrames for each metric\n",
    "df_dicescore = pd.DataFrame(columns=support_set_sizes)\n",
    "df_accuracy = pd.DataFrame(columns=support_set_sizes)\n",
    "df_sensitivity = pd.DataFrame(columns=support_set_sizes)\n",
    "df_precision = pd.DataFrame(columns=support_set_sizes)\n",
    "df_jaccard = pd.DataFrame(columns=support_set_sizes)\n",
    "\n",
    "for image, label in d_test:\n",
    "    dice_scores = {}\n",
    "    acc = {}\n",
    "    sens = {}\n",
    "    prec = {}\n",
    "    jac = {}\n",
    "    for N in support_set_sizes:\n",
    "        # Randomly select N indices for both images and labels\n",
    "        random_indices = random.sample(range(len(d_support)), N)\n",
    "        random_support = [(d_support[i][0], d_support[i][1]) for i in random_indices]\n",
    "        \n",
    "        # Unzip the random_support into images and labels\n",
    "        support_images, support_labels = zip(*random_support)\n",
    "        \n",
    "        # Convert support_images into a PyTorch tensor and move it to the device\n",
    "        support_images = torch.stack(support_images).to(device)\n",
    "        support_labels = torch.stack(support_labels).to(device)\n",
    "        \n",
    "        # Call the function for inference\n",
    "        vals = inferencesupport(model, image, label, support_images, support_labels)\n",
    "        \n",
    "        # Store the metrics\n",
    "        dice_scores[N] = vals['score'] if 'score' in vals else None\n",
    "        acc[N] = vals['accuracy'] if 'accuracy' in vals else None\n",
    "        sens[N] = vals['sensitivity'] if 'sensitivity' in vals else None\n",
    "        prec[N] = vals['precision'] if 'precision' in vals else None\n",
    "        jac[N] = vals['jaccard'] if 'jaccard' in vals else None\n",
    "\n",
    "    df_dicescore = pd.concat([df_dicescore, pd.DataFrame(dice_scores, index=[0])], ignore_index=True)\n",
    "    df_accuracy = pd.concat([df_accuracy, pd.DataFrame(acc, index=[0])], ignore_index=True)\n",
    "    df_sensitivity = pd.concat([df_sensitivity, pd.DataFrame(sens, index=[0])], ignore_index=True)\n",
    "    df_precision = pd.concat([df_precision, pd.DataFrame(prec, index=[0])], ignore_index=True)\n",
    "    df_jaccard = pd.concat([df_jaccard, pd.DataFrame(jac, index=[0])], ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0579a419",
   "metadata": {},
   "source": [
    "df_dicescore.to_csv('random_dicescore_with.csv', index=False)\n",
    "df_accuracy.to_csv('random_accuracy_with.csv', index=False)\n",
    "df_sensitivity.to_csv('random_sensitivity_with.csv', index=False)\n",
    "df_precision.to_csv('random_precision_with.csv', index=False)\n",
    "df_jaccard.to_csv('random_jaccard_with.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9bc22570",
   "metadata": {},
   "source": [
    "meandice_df = pd.DataFrame(df_dicescore.mean().to_dict(),index=['DiceScore'])\n",
    "meanacc_df = pd.DataFrame(df_accuracy.mean().to_dict(),index=['Accuracy'])\n",
    "meansens_df=pd.DataFrame(df_sensitivity.mean().to_dict(),index=['Sensitivity'])\n",
    "meanprec_df= pd.DataFrame(df_precision.mean().to_dict(),index=['Precision'])\n",
    "meanjac_df = pd.DataFrame(df_jaccard.mean().to_dict(),index=['Jaccard'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "316ecd18",
   "metadata": {},
   "source": [
    "df=[meandice_df,meanacc_df,meansens_df,meanprec_df,meanjac_df]\n",
    "result=pd.concat(df)\n",
    "result"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dffd791b",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "sns.lineplot(result.transpose())\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b7e140cd",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "#df_dicescore.plot(kind='box')\n",
    "ax = sns.boxplot(data=df_dicescore, palette='pastel')\n",
    "plt.title('Boxplot of dicescore of support set size(N)')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bf6b35f6",
   "metadata": {},
   "source": [
    "### Ensemble with random support set"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# helpful function to sample support data\n",
    "def sample_support(seed):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idxs = rng.integers(0,len(d_support), size=support_size)\n",
    "    support_images, support_labels = zip(*[d_support[i] for i in idxs])\n",
    "    support_images = torch.stack(support_images).to(device)\n",
    "    support_labels = torch.stack(support_labels).to(device)\n",
    "    return support_images, support_labels"
   ],
   "id": "2581eaa7f1cd054f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd4f28b4",
   "metadata": {},
   "source": [
    "d_support = JNU_FMI(support_input_folder, label=support_mask_folder)\n",
    "d_test = JNU_FMI(test_input_folder, label=test_mask_folder)\n",
    "\n",
    "\n",
    "support_sizes = [4,8,16,32,64]  # Adjust according to your requirements\n",
    "n_ensemble_values = [3, 5, 8, 10]  # Adjust according to your requirements\n",
    "# \n",
    "# Initialize a dictionary to store average Dice scores\n",
    "average_dice_scores = {}\n",
    "\n",
    "# Iterate over different support sizes\n",
    "for support_size in support_sizes:\n",
    "    random_indices = random.sample(range(len(d_support)), N)\n",
    "    random_support = [(d_support[i][0], d_support[i][1]) for i in random_indices]\n",
    "\n",
    "    # Unzip the random_support into images and labels\n",
    "    support_images, support_labels = zip(*random_support)\n",
    "\n",
    "    # Convert support_images into a PyTorch tensor and move it to the device\n",
    "    support_images = torch.stack(support_images).to(device)\n",
    "    support_labels = torch.stack(support_labels).to(device)\n",
    "    # Iterate over different ensemble sizes\n",
    "    for n_ensemble in n_ensemble_values:\n",
    "\n",
    "        # get various support sets\n",
    "        seeds = range(n_ensemble)\n",
    "        supports = {\n",
    "            seed: sample_support(seed)\n",
    "            for seed in range(n_ensemble)\n",
    "        }\n",
    "\n",
    "        all_scores = []\n",
    "\n",
    "        # go through the number of experiments\n",
    "        for image, label in d_test:\n",
    "\n",
    "            # Initialize a list to store scores for each ensemble\n",
    "            ensemble_scores = []\n",
    "\n",
    "            # go through the number of predictions we will ensemble\n",
    "            for j in range(n_ensemble):\n",
    "                # get support set\n",
    "                #support_images, support_labels = sample_support(j)\n",
    "\n",
    "                # perform inference\n",
    "                vals = inference(model, image, label, support_images[:support_size], support_labels[:support_size])\n",
    "                dice_score_value = vals['score'] if 'score' in vals else None\n",
    "                ensemble_scores.append(dice_score_value)\n",
    "\n",
    "            # Calculate the average score for this image across all ensembles\n",
    "            average_score = sum(ensemble_scores) / n_ensemble\n",
    "\n",
    "            # Append the score of this prediction to the list\n",
    "            all_scores.append(average_score)\n",
    "\n",
    "        # Calculate the average score across all predictions\n",
    "        average_dice_score = sum(all_scores) / len(all_scores)\n",
    "\n",
    "        # Store the average Dice score in the dictionary\n",
    "        average_dice_scores[(support_size, n_ensemble)] = average_dice_score\n",
    "\n",
    "# Print and/or save the dictionary as needed\n",
    "print(\"Average Dice Scores:\")\n",
    "for key, value in average_dice_scores.items():\n",
    "    print(f\"Support Size: {key[0]}, Ensemble Size: {key[1]}, Average Dice Score: {value:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ee1babf6fdee9431",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
