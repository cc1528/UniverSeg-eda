{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pathlib\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "import umap.umap_ as umap\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, pairwise_distances\n",
    "from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "symp_value = 76   # Grayscale value for images with pubic symphysis and background mask only\n",
    "head_value = 150  # Grayscale value for images with head mask and background mask\n",
    "combined_value = 200  # Arbitrary value for images that have all labels\n",
    "background_value = 0 #Grayscale value for images with background label only \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Load the final ensemble model\n",
    "def load_ensemble_model(model_path, device):\n",
    "    model = smp.Unet(encoder_name=\"efficientnet-b0\", encoder_weights=None, in_channels=1, classes=3)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def get_feature_extractor(model):\n",
    "    # Use the encoder part for feature extraction\n",
    "    return model.encoder\n",
    "\n",
    "# Define the preprocessing transform\n",
    "preprocess = A.Compose([\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,), max_pixel_value=255.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Function to load and preprocess an image\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"L\")\n",
    "    image = np.array(image)\n",
    "    augmented = preprocess(image=image)\n",
    "    return augmented['image'].unsqueeze(0)\n",
    "\n",
    "final_model_path = 'ensemble_model_final.pth'\n",
    "ensemble_model = load_ensemble_model(final_model_path, device)\n",
    "\n",
    "# Get the feature extractor\n",
    "feature_extractor = get_feature_extractor(ensemble_model)\n",
    "\n",
    "# Function to extract features from the 10th layer\n",
    "def extract_10th_layer_features(feature_extractor, input_tensor):\n",
    "    features = []\n",
    "    x = input_tensor\n",
    "\n",
    "    # Iterate through the layers of the encoder\n",
    "    x = feature_extractor._conv_stem(x)\n",
    "    x = feature_extractor._bn0(x)\n",
    "\n",
    "    for idx, block in enumerate(feature_extractor._blocks):\n",
    "        x = block(x)\n",
    "        if idx == 9:  # 10th layer\n",
    "            features.append(x)\n",
    "            break\n",
    "\n",
    "    return features\n",
    "\n",
    "# Function to extract features with labels\n",
    "def extract_features_with_labels(image_paths: List[pathlib.Path], label_paths: List[pathlib.Path], device) -> Dict[int, List[Tuple[pathlib.Path, np.ndarray]]]:\n",
    "    features = defaultdict(list)\n",
    "    num_processed = 0\n",
    "    label_counts = defaultdict(int)\n",
    "\n",
    "    for img_path, label_path in zip(image_paths, label_paths):\n",
    "        try:\n",
    "            img = load_image(img_path).to(device)  # Load and preprocess image\n",
    "            with torch.no_grad():\n",
    "                feat = extract_10th_layer_features(feature_extractor, img)\n",
    "            feat = feat[0].cpu().numpy().squeeze().flatten()  # Extract the feature from the list\n",
    "\n",
    "            mask = Image.open(label_path).convert('L')\n",
    "            mask = np.array(mask)\n",
    "            unique_labels = set(np.unique(mask))\n",
    "\n",
    "            #print(f\"Image {img_path}: Unique labels in mask: {unique_labels}\")  # Debugging print\n",
    "\n",
    "            if unique_labels == {background_value}:\n",
    "                features[background_value].append((img_path, feat))\n",
    "                label_counts[background_value] += 1\n",
    "            else:\n",
    "                if symp_value in unique_labels and head_value in unique_labels:\n",
    "                    features[combined_value].append((img_path, feat))\n",
    "                    label_counts[combined_value] += 1\n",
    "                else:\n",
    "                    if symp_value in unique_labels:\n",
    "                        features[symp_value].append((img_path, feat))\n",
    "                        label_counts[symp_value] += 1\n",
    "                    if head_value in unique_labels:\n",
    "                        features[head_value].append((img_path, feat))\n",
    "                        label_counts[head_value] += 1\n",
    "\n",
    "            num_processed += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {img_path}: {e}\")\n",
    "\n",
    "    #print(f\"Total number of images processed: {num_processed}\")\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"Label {label}: {count} images\")\n",
    "\n",
    "    return features\n",
    "\n",
    "# Function to gather all image and label paths\n",
    "def gather_image_label_paths(image_dir: pathlib.Path, label_dir: pathlib.Path):\n",
    "    image_paths = list(image_dir.glob('*.png'))\n",
    "    label_paths = [label_dir / (img_path.stem + '_mask.png') for img_path in image_paths]\n",
    "    return image_paths, label_paths\n",
    "\n"
   ],
   "id": "44b0c29e6fbe232"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#validation scores on clustering",
   "id": "14a7a54363761d82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "support_input_folder = r'C:\\Users\\cinth\\Documentos\\ams\\data_science\\actual_thesis\\codes\\MedSAM_Universeg_2024\\datasets\\data\\dataset_complete_2\\partitioned_dataset_original\\images\\train'\n",
    "support_mask_folder = r'C:\\Users\\cinth\\Documentos\\ams\\data_science\\actual_thesis\\codes\\MedSAM_Universeg_2024\\datasets\\data\\dataset_complete_2\\partitioned_dataset_original\\masks\\train'\n",
    "\n",
    "image_dir = pathlib.Path(support_input_folder)\n",
    "label_dir = pathlib.Path(support_mask_folder)\n"
   ],
   "id": "65d6a780426a7ff7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "image_paths, label_paths = gather_image_label_paths(image_dir, label_dir)\n",
    "features = extract_features_with_labels(image_paths, label_paths, device)\n",
    "\n",
    "# Iterate over each unique label and perform clustering\n",
    "for label in features:\n",
    "    print(f\"Processing label {label}...\")\n",
    "\n",
    "    subset_features = np.array([feat for _, feat in features[label]])\n",
    "\n",
    "    # Perform UMAP to reduce to 2 dimensions\n",
    "    umap_model = umap.UMAP(n_components=2, random_state=42)\n",
    "    reduced_features_umap = umap_model.fit_transform(subset_features)\n",
    "\n",
    "    # Determine the optimal number of clusters using the elbow method and silhouette score\n",
    "    wcss = []\n",
    "    silhouette_scores = []\n",
    "    for i in range(2, 15):  \n",
    "        kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
    "        kmeans.fit(reduced_features_umap)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "        cluster_labels = kmeans.predict(reduced_features_umap)\n",
    "        silhouette_scores.append(silhouette_score(reduced_features_umap, cluster_labels))\n",
    "\n",
    "    # # Plot WCSS (Elbow Method)\n",
    "    # plt.plot(range(2, 15), wcss)\n",
    "    # plt.title(f'Elbow Method for Label {label}')\n",
    "    # plt.xlabel('Number of clusters')\n",
    "    # plt.ylabel('WCSS')\n",
    "    # plt.show()\n",
    "    # \n",
    "    # # Plot Silhouette Scores\n",
    "    # plt.plot(range(2, 15), silhouette_scores)\n",
    "    # plt.title(f'Silhouette Score Method for Label {label}')\n",
    "    # plt.xlabel('Number of clusters')\n",
    "    # plt.ylabel('Silhouette Score')\n",
    "    # plt.show()\n",
    "\n",
    "    # Print WCSS and silhouette scores\n",
    "    print(f\"WCSS for Label {label}: {wcss}\")\n",
    "    print(f\"Silhouette Scores for Label {label}: {silhouette_scores}\")\n",
    "\n",
    "    # Choose the optimal number of clusters based on the highest silhouette score\n",
    "    optimal_k = silhouette_scores.index(max(silhouette_scores)) + 2  # +2 because range starts from 2\n",
    "    print(f\"Optimal number of clusters for Label {label}: {optimal_k}\")\n",
    "\n",
    "    # Apply K-means with the chosen number of clusters\n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(reduced_features_umap)\n",
    "\n",
    "    # Visualize the clusters using UMAP\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    unique_cluster_labels = np.unique(cluster_labels)\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(unique_cluster_labels)))\n",
    "        \n",
    "    for cl_label, color in zip(unique_cluster_labels, colors):\n",
    "        indices = np.where(cluster_labels == cl_label)\n",
    "        plt.scatter(reduced_features_umap[indices, 0], reduced_features_umap[indices, 1], label=f'Cluster {cl_label}', c=[color])\n",
    "\n",
    "    # # UMAP Visualization of Clusters for Label\n",
    "    # plt.title(f'UMAP Visualization of Clusters for Label {label}')\n",
    "    # plt.xlabel('UMAP Component 1')\n",
    "    # plt.ylabel('UMAP Component 2')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    # Calculate Davies-Bouldin Index\n",
    "    db_index = davies_bouldin_score(reduced_features_umap, cluster_labels)\n",
    "    print(f\"Davies-Bouldin Index for Label {label}: {db_index}\")\n",
    "\n",
    "    # Calculate Calinski-Harabasz Index\n",
    "    ch_index = calinski_harabasz_score(reduced_features_umap, cluster_labels)\n",
    "    print(f\"Calinski-Harabasz Index for Label {label}: {ch_index}\")\n",
    "\n"
   ],
   "id": "fc36341f9562c34f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "## Apply clustering and image selection ->select images 20% of the training dataset",
   "id": "f00090fcd23fb213"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define 'num_clusters' and 'num_images' for each label\n",
    "config = {\n",
    "\n",
    "    combined_value: {'num_clusters': 14, 'num_images': 33},\n",
    "    symp_value: {'num_clusters': 4, 'num_images': 10},\n",
    "    head_value: {'num_clusters': 4, 'num_images': 32},\n",
    "    background_value: {'num_clusters': 5, 'num_images': 24} \n",
    "}\n",
    "\n",
    "# Apply clustering and image selection based on the configuration\n",
    "selected_image_paths = []  # List to store selected image paths\n",
    "image_counts = {}  # Dictionary to store counts of selected images per label\n",
    "\n",
    "for label, settings in config.items():\n",
    "    print(f\"Processing label {label} with settings: clusters={settings['num_clusters']}, images={settings['num_images']}...\")\n",
    "\n",
    "    subset_features = np.array([feat for _, feat in features[label]])\n",
    "    umap_model = umap.UMAP(n_components=2, random_state=42)\n",
    "    reduced_features_umap = umap_model.fit_transform(subset_features)\n",
    "\n",
    "    # Apply KMeans with the number of clusters \n",
    "    kmeans = KMeans(n_clusters=settings['num_clusters'], random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(reduced_features_umap)\n",
    "\n",
    "    count = 0  \n",
    "\n",
    "    # Find medoids and select closest images\n",
    "    for cluster_index in range(settings['num_clusters']):\n",
    "        cluster_points = reduced_features_umap[cluster_labels == cluster_index]\n",
    "        medoid_index = np.argmin(pairwise_distances(cluster_points, metric='euclidean').sum(axis=1))\n",
    "        medoid = cluster_points[medoid_index]\n",
    "\n",
    "        # Calculate distances to medoid and sort\n",
    "        distances = np.linalg.norm(cluster_points - medoid, axis=1)\n",
    "        sorted_indices = np.argsort(distances)\n",
    "\n",
    "        # Select medoid and the number of closest images specified in the config\n",
    "        indices_to_select = sorted_indices[:settings['num_images'] + 1]  \n",
    "        for idx in indices_to_select:\n",
    "            if idx < len(features[label]):\n",
    "                selected_image_paths.append(features[label][idx][0])\n",
    "                count += 1\n",
    "\n",
    "    # Store the count of selected images for the current label\n",
    "    image_counts[label] = count\n",
    "\n",
    "# Print the counts of selected images per label\n",
    "for label, count in image_counts.items():\n",
    "    print(f\"Label {label}: {count} images selected\")\n",
    "\n",
    "# Convert to DataFrame and save to CSV\n",
    "df = pd.DataFrame(selected_image_paths, columns=['Image_Path'])\n",
    "df.to_csv('medoids_and_samples_final_30.csv', index=False)\n",
    "print(\"Results saved to 'medoids_and_samples_final_20.csv'\")\n",
    "\n"
   ],
   "id": "bc8b50f67db7f1be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#Save the representative in one folder",
   "id": "e51dbbf60bc1aed8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "# Define input and mask folders for the dataset\n",
    "support_input_folder = r'C:\\Users\\cinth\\Documentos\\ams\\data_science\\actual_thesis\\codes\\MedSAM_Universeg_2024\\datasets\\data\\dataset_complete\\partitioned_dataset_original\\images\\train'\n",
    "support_mask_folder = r'C:\\Users\\cinth\\Documentos\\ams\\data_science\\actual_thesis\\codes\\MedSAM_Universeg_2024\\datasets\\data\\dataset_complete\\partitioned_dataset_original\\masks\\train'\n",
    "\n",
    "# Path to the CSV file containing the selected image paths\n",
    "csv_file_path = './medoids_and_samples_final_20.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Print the content of the DataFrame to debug\n",
    "print(\"DataFrame contents:\")\n",
    "print(df)\n",
    "\n",
    "# Define the source folders for images and masks\n",
    "source_image_folder = pathlib.Path(support_input_folder)\n",
    "source_mask_folder = pathlib.Path(support_mask_folder)\n",
    "\n",
    "# Define the destination folders for selected images and masks\n",
    "dest_image_folder = pathlib.Path('./ef_selected_images_final_20')\n",
    "dest_mask_folder = pathlib.Path('./ef_selected_masks_final_20')\n",
    "\n",
    "# Create destination directories if they don't exist\n",
    "dest_image_folder.mkdir(parents=True, exist_ok=True)\n",
    "dest_mask_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy images and their respective masks to the destination folder\n",
    "total_images_copied = 0\n",
    "total_masks_copied = 0\n",
    "\n",
    "for col in df.columns:\n",
    "    for image_name in df[col].dropna():\n",
    "        # Ensure the image name is a string path\n",
    "        if isinstance(image_name, str) or isinstance(image_name, pathlib.PurePath):\n",
    "            image_path = pathlib.Path(image_name)\n",
    "            mask_path = source_mask_folder / (image_path.stem + '_mask.png')\n",
    "            \n",
    "            # Check if the image and mask exist\n",
    "            image_exists = image_path.exists()\n",
    "            mask_exists = mask_path.exists()\n",
    "            \n",
    "            print(f\"Processing image: {image_path}\")\n",
    "            print(f\"Image exists: {image_exists}, Mask exists: {mask_exists}\")\n",
    "            \n",
    "            if image_exists and mask_exists:\n",
    "                # Copy the image\n",
    "                shutil.copy(image_path, dest_image_folder / image_path.name)\n",
    "                total_images_copied += 1\n",
    "                # Copy the mask\n",
    "                shutil.copy(mask_path, dest_mask_folder / mask_path.name)\n",
    "                total_masks_copied += 1\n",
    "            else:\n",
    "                print(f\"Error: Image or mask not found for {image_path}\")\n",
    "                if not image_exists:\n",
    "                    print(f\"Image missing: {image_path}\")\n",
    "                if not mask_exists:\n",
    "                    print(f\"Mask missing: {mask_path}\")\n",
    "                # Stop execution\n",
    "                raise FileNotFoundError(f\"Image or mask not found for {image_path}\")\n",
    "        else:\n",
    "            print(f\"Skipping invalid image path: {image_name}\")\n",
    "\n",
    "print(f\"Total images copied: {total_images_copied}\")\n",
    "print(f\"Total masks copied: {total_masks_copied}\")\n",
    "print(f\"Images and masks have been copied to '{dest_image_folder}' and '{dest_mask_folder}' respectively.\")\n"
   ],
   "id": "7adee5f626f37c90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3acb41e2137b5e7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f7c852a33d5d5a87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2d5d37e2a48aca1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
